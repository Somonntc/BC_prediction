{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BitCoin Prediction using Deep Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Load and read the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading/Reading in the Data\n",
    "df = pd.read_csv(\"BTC-USD.csv\")\n",
    "\n",
    "# Data Preprocessing\n",
    "### Setting the datetime index as the date, only selecting the 'Close' column, then only the last 1000 closing prices.\n",
    "df = df.set_index(\"Date\")[['Close']].tail(1000)\n",
    "df = df.set_index(pd.to_datetime(df.index))\n",
    "\n",
    "# Normalizing/Scaling the Data\n",
    "scaler = MinMaxScaler()\n",
    "df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns, index=df.index)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Note: we are only selecting the last 1,000 days of Bitcoin prices because those days are the most representative of the current Cryptocurrency market."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def visualize_training_results(results):\n",
    "    \"\"\"\n",
    "    Plots the loss and accuracy for the training and testing data\n",
    "    \"\"\"\n",
    "    history = results.history\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(history['val_loss'])\n",
    "    plt.plot(history['loss'])\n",
    "    plt.legend(['val_loss', 'loss'])\n",
    "    plt.title('Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.plot(history['val_accuracy'])\n",
    "    plt.plot(history['accuracy'])\n",
    "    plt.legend(['val_accuracy', 'accuracy'])\n",
    "    plt.title('Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def split_sequence(seq, n_steps_in, n_steps_out):\n",
    "    \"\"\"\n",
    "    Splits the univariate time sequence\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    \n",
    "    for i in range(len(seq)):\n",
    "        end = i + n_steps_in\n",
    "        out_end = end + n_steps_out\n",
    "        \n",
    "        if out_end > len(seq):\n",
    "            break\n",
    "        \n",
    "        seq_x, seq_y = seq[i:end], seq[end:out_end]\n",
    "        \n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "\n",
    "def layer_maker(n_layers, n_nodes, activation, drop=None, d_rate=.5):\n",
    "    \"\"\"\n",
    "    Create a specified number of hidden layers for an RNN\n",
    "    Optional: Adds regularization option, dropout layer to prevent potential overfitting if necessary\n",
    "    \"\"\"\n",
    "    \n",
    "    # Creating the specified number of hidden layers with the specified number of nodes\n",
    "    for x in range(1,n_layers+1):\n",
    "        model.add(LSTM(n_nodes, activation=activation, return_sequences=True))\n",
    "\n",
    "        # Adds a Dropout layer after every Nth hidden layer (the 'drop' variable)\n",
    "        try:\n",
    "            if x % drop == 0:\n",
    "                model.add(Dropout(d_rate))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many periods looking back to train\n",
    "n_per_in  = 30\n",
    "\n",
    "# How many periods ahead to predict\n",
    "n_per_out = 10\n",
    "\n",
    "# Features (in this case it's 1 because there is only one feature: price)\n",
    "n_features = 1\n",
    "\n",
    "# Splitting the data into appropriate sequences\n",
    "X, y = split_sequence(list(df.Close), n_per_in, n_per_out)\n",
    "\n",
    "# Reshaping the X variable from 2D to 3D\n",
    "X = X.reshape((X.shape[0], X.shape[1], n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 30, 30)            3840      \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 30, 12)            2064      \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 30, 12)            1200      \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 30, 12)            1200      \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 30, 12)            1200      \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 30, 12)            1200      \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                (None, 30, 12)            1200      \n",
      "_________________________________________________________________\n",
      "lstm_8 (LSTM)                (None, 10)                920       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                110       \n",
      "=================================================================\n",
      "Total params: 12,934\n",
      "Trainable params: 12,934\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the model\n",
    "model = Sequential()\n",
    "\n",
    "# Activation\n",
    "activ = \"softsign\"\n",
    "\n",
    "# Input layer\n",
    "model.add(LSTM(30, activation=activ, return_sequences=True, input_shape=(n_per_in, n_features)))\n",
    "\n",
    "# Hidden layers\n",
    "layer_maker(n_layers=6, n_nodes=12, activation=activ)\n",
    "\n",
    "# Final Hidden layer\n",
    "model.add(LSTM(10, activation=activ))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(n_per_out))\n",
    "\n",
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mean_squared_error', optimizer=\"Adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "Train on 864 samples, validate on 97 samples\n",
      "Epoch 1/800\n",
      "864/864 [==============================] - 14s 16ms/step - loss: 0.0982 - acc: 0.1331 - val_loss: 0.0947 - val_acc: 0.3402\n",
      "Epoch 2/800\n",
      "864/864 [==============================] - 4s 5ms/step - loss: 0.0506 - acc: 0.1551 - val_loss: 0.0288 - val_acc: 0.3402\n",
      "Epoch 3/800\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 0.0349 - acc: 0.0903 - val_loss: 0.0193 - val_acc: 0.0619\n",
      "Epoch 4/800\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 0.0267 - acc: 0.1019 - val_loss: 0.0040 - val_acc: 0.0515\n",
      "Epoch 5/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0155 - acc: 0.0961 - val_loss: 0.0030 - val_acc: 0.0619\n",
      "Epoch 6/800\n",
      "864/864 [==============================] - 5s 5ms/step - loss: 0.0129 - acc: 0.1088 - val_loss: 0.0061 - val_acc: 0.1753\n",
      "Epoch 7/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0120 - acc: 0.1389 - val_loss: 0.0048 - val_acc: 0.1443\n",
      "Epoch 8/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0107 - acc: 0.1250 - val_loss: 0.0035 - val_acc: 0.2165\n",
      "Epoch 9/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0097 - acc: 0.1505 - val_loss: 0.0023 - val_acc: 0.1753\n",
      "Epoch 10/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0094 - acc: 0.1817 - val_loss: 0.0036 - val_acc: 0.2062\n",
      "Epoch 11/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0089 - acc: 0.1678 - val_loss: 0.0034 - val_acc: 0.2062A: 2s - loss: 0.006\n",
      "Epoch 12/800\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 0.0083 - acc: 0.1759 - val_loss: 0.0023 - val_acc: 0.1237\n",
      "Epoch 13/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0082 - acc: 0.1725 - val_loss: 0.0022 - val_acc: 0.1753\n",
      "Epoch 14/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0073 - acc: 0.1875 - val_loss: 0.0024 - val_acc: 0.1443\n",
      "Epoch 15/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0072 - acc: 0.1782 - val_loss: 0.0025 - val_acc: 0.1856\n",
      "Epoch 16/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0069 - acc: 0.1840 - val_loss: 0.0036 - val_acc: 0.2680\n",
      "Epoch 17/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0065 - acc: 0.1794 - val_loss: 0.0038 - val_acc: 0.1649\n",
      "Epoch 18/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0065 - acc: 0.1701 - val_loss: 0.0025 - val_acc: 0.1340\n",
      "Epoch 19/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0060 - acc: 0.1852 - val_loss: 0.0026 - val_acc: 0.14430059 - acc:\n",
      "Epoch 20/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0057 - acc: 0.1782 - val_loss: 0.0033 - val_acc: 0.1340\n",
      "Epoch 21/800\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 0.0056 - acc: 0.1690 - val_loss: 0.0028 - val_acc: 0.1443\n",
      "Epoch 22/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0054 - acc: 0.1725 - val_loss: 0.0028 - val_acc: 0.1443\n",
      "Epoch 23/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0054 - acc: 0.1806 - val_loss: 0.0031 - val_acc: 0.1443\n",
      "Epoch 24/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0056 - acc: 0.1759 - val_loss: 0.0032 - val_acc: 0.1340\n",
      "Epoch 25/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0056 - acc: 0.1794 - val_loss: 0.0029 - val_acc: 0.1649\n",
      "Epoch 26/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0052 - acc: 0.1690 - val_loss: 0.0032 - val_acc: 0.1753\n",
      "Epoch 27/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0051 - acc: 0.1806 - val_loss: 0.0032 - val_acc: 0.1649\n",
      "Epoch 28/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0052 - acc: 0.1701 - val_loss: 0.0045 - val_acc: 0.1546\n",
      "Epoch 29/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0049 - acc: 0.1829 - val_loss: 0.0030 - val_acc: 0.1649\n",
      "Epoch 30/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0050 - acc: 0.1678 - val_loss: 0.0035 - val_acc: 0.1546\n",
      "Epoch 31/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0049 - acc: 0.1817 - val_loss: 0.0034 - val_acc: 0.1546\n",
      "Epoch 32/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0050 - acc: 0.1667 - val_loss: 0.0035 - val_acc: 0.1649\n",
      "Epoch 33/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0047 - acc: 0.1644 - val_loss: 0.0037 - val_acc: 0.1753\n",
      "Epoch 34/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0045 - acc: 0.1736 - val_loss: 0.0035 - val_acc: 0.1237\n",
      "Epoch 35/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0046 - acc: 0.1586 - val_loss: 0.0042 - val_acc: 0.1753\n",
      "Epoch 36/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0044 - acc: 0.1921 - val_loss: 0.0045 - val_acc: 0.1443\n",
      "Epoch 37/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0045 - acc: 0.1713 - val_loss: 0.0037 - val_acc: 0.1649\n",
      "Epoch 38/800\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 0.0043 - acc: 0.1481 - val_loss: 0.0046 - val_acc: 0.1649\n",
      "Epoch 39/800\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 0.0041 - acc: 0.1794 - val_loss: 0.0037 - val_acc: 0.1649\n",
      "Epoch 40/800\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 0.0042 - acc: 0.1748 - val_loss: 0.0032 - val_acc: 0.1649\n",
      "Epoch 41/800\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 0.0040 - acc: 0.1921 - val_loss: 0.0036 - val_acc: 0.1340\n",
      "Epoch 42/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0038 - acc: 0.1678 - val_loss: 0.0042 - val_acc: 0.1237\n",
      "Epoch 43/800\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 0.0041 - acc: 0.1817 - val_loss: 0.0034 - val_acc: 0.1134\n",
      "Epoch 44/800\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 0.0038 - acc: 0.1678 - val_loss: 0.0041 - val_acc: 0.1443\n",
      "Epoch 45/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0038 - acc: 0.1852 - val_loss: 0.0047 - val_acc: 0.1340\n",
      "Epoch 46/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0036 - acc: 0.1817 - val_loss: 0.0032 - val_acc: 0.1237\n",
      "Epoch 47/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0037 - acc: 0.1620 - val_loss: 0.0031 - val_acc: 0.1340\n",
      "Epoch 48/800\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 0.0036 - acc: 0.2014 - val_loss: 0.0036 - val_acc: 0.0825\n",
      "Epoch 49/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0035 - acc: 0.1736 - val_loss: 0.0031 - val_acc: 0.1753\n",
      "Epoch 50/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0035 - acc: 0.1516 - val_loss: 0.0032 - val_acc: 0.1546\n",
      "Epoch 51/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0033 - acc: 0.1875 - val_loss: 0.0032 - val_acc: 0.1134\n",
      "Epoch 52/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0032 - acc: 0.1956 - val_loss: 0.0038 - val_acc: 0.1340\n",
      "Epoch 53/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0034 - acc: 0.1400 - val_loss: 0.0034 - val_acc: 0.1031\n",
      "Epoch 54/800\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 0.0032 - acc: 0.1968 - val_loss: 0.0031 - val_acc: 0.0928\n",
      "Epoch 55/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0030 - acc: 0.1227 - val_loss: 0.0032 - val_acc: 0.1443\n",
      "Epoch 56/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0031 - acc: 0.1447 - val_loss: 0.0029 - val_acc: 0.1134\n",
      "Epoch 57/800\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 0.0030 - acc: 0.1644 - val_loss: 0.0037 - val_acc: 0.0825\n",
      "Epoch 58/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0031 - acc: 0.1505 - val_loss: 0.0031 - val_acc: 0.1443\n",
      "Epoch 59/800\n",
      "864/864 [==============================] - 5s 6ms/step - loss: 0.0031 - acc: 0.1632 - val_loss: 0.0038 - val_acc: 0.0825\n",
      "Epoch 60/800\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 0.0032 - acc: 0.2130 - val_loss: 0.0032 - val_acc: 0.1340\n",
      "Epoch 61/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0029 - acc: 0.1308 - val_loss: 0.0033 - val_acc: 0.1443\n",
      "Epoch 62/800\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 0.0029 - acc: 0.1713 - val_loss: 0.0027 - val_acc: 0.0928\n",
      "Epoch 63/800\n",
      "864/864 [==============================] - 6s 6ms/step - loss: 0.0029 - acc: 0.1366 - val_loss: 0.0032 - val_acc: 0.0928\n",
      "Epoch 64/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0029 - acc: 0.2083 - val_loss: 0.0027 - val_acc: 0.1031\n",
      "Epoch 65/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0029 - acc: 0.1296 - val_loss: 0.0037 - val_acc: 0.0928\n",
      "Epoch 66/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0028 - acc: 0.1944 - val_loss: 0.0035 - val_acc: 0.2577\n",
      "Epoch 67/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0029 - acc: 0.1701 - val_loss: 0.0035 - val_acc: 0.1031\n",
      "Epoch 68/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0029 - acc: 0.1516 - val_loss: 0.0031 - val_acc: 0.1340\n",
      "Epoch 69/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0029 - acc: 0.2014 - val_loss: 0.0028 - val_acc: 0.0928\n",
      "Epoch 70/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0027 - acc: 0.1655 - val_loss: 0.0038 - val_acc: 0.1237\n",
      "Epoch 71/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0027 - acc: 0.1424 - val_loss: 0.0032 - val_acc: 0.0825\n",
      "Epoch 72/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0027 - acc: 0.1412 - val_loss: 0.0031 - val_acc: 0.1134\n",
      "Epoch 73/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0027 - acc: 0.1562 - val_loss: 0.0035 - val_acc: 0.0722\n",
      "Epoch 74/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0025 - acc: 0.1829 - val_loss: 0.0034 - val_acc: 0.1134\n",
      "Epoch 75/800\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0026 - acc: 0.1551 - val_loss: 0.0034 - val_acc: 0.0928\n",
      "Epoch 76/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0025 - acc: 0.1944 - val_loss: 0.0036 - val_acc: 0.0825\n",
      "Epoch 77/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0026 - acc: 0.1528 - val_loss: 0.0032 - val_acc: 0.2990\n",
      "Epoch 78/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0027 - acc: 0.1678 - val_loss: 0.0038 - val_acc: 0.0722\n",
      "Epoch 79/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0027 - acc: 0.1852 - val_loss: 0.0032 - val_acc: 0.1031\n",
      "Epoch 80/800\n",
      "864/864 [==============================] - 6s 7ms/step - loss: 0.0025 - acc: 0.1806 - val_loss: 0.0038 - val_acc: 0.1031\n",
      "Epoch 81/800\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0026 - acc: 0.1273 - val_loss: 0.0036 - val_acc: 0.2680\n",
      "Epoch 82/800\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0027 - acc: 0.1400 - val_loss: 0.0032 - val_acc: 0.1134\n",
      "Epoch 83/800\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0026 - acc: 0.1759 - val_loss: 0.0029 - val_acc: 0.1031\n",
      "Epoch 84/800\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0026 - acc: 0.1852 - val_loss: 0.0040 - val_acc: 0.0825\n",
      "Epoch 85/800\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0025 - acc: 0.1748 - val_loss: 0.0037 - val_acc: 0.0825\n",
      "Epoch 86/800\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0024 - acc: 0.1933 - val_loss: 0.0034 - val_acc: 0.1237\n",
      "Epoch 87/800\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0025 - acc: 0.1458 - val_loss: 0.0041 - val_acc: 0.3299\n",
      "Epoch 88/800\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0026 - acc: 0.1840 - val_loss: 0.0042 - val_acc: 0.0928\n",
      "Epoch 89/800\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0024 - acc: 0.1042 - val_loss: 0.0034 - val_acc: 0.1237\n",
      "Epoch 90/800\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0024 - acc: 0.1678 - val_loss: 0.0044 - val_acc: 0.0928\n",
      "Epoch 91/800\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0025 - acc: 0.1331 - val_loss: 0.0032 - val_acc: 0.2680\n",
      "Epoch 92/800\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0025 - acc: 0.1528 - val_loss: 0.0036 - val_acc: 0.0928\n",
      "Epoch 93/800\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0024 - acc: 0.1829 - val_loss: 0.0037 - val_acc: 0.0928\n",
      "Epoch 94/800\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0026 - acc: 0.1817 - val_loss: 0.0036 - val_acc: 0.0619\n",
      "Epoch 95/800\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0024 - acc: 0.1285 - val_loss: 0.0035 - val_acc: 0.1546\n",
      "Epoch 96/800\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0025 - acc: 0.1944 - val_loss: 0.0035 - val_acc: 0.0722\n",
      "Epoch 97/800\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0025 - acc: 0.1829 - val_loss: 0.0038 - val_acc: 0.1959\n",
      "Epoch 98/800\n",
      "864/864 [==============================] - 7s 9ms/step - loss: 0.0025 - acc: 0.1088 - val_loss: 0.0035 - val_acc: 0.0722\n",
      "Epoch 99/800\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0025 - acc: 0.1748 - val_loss: 0.0037 - val_acc: 0.0825\n",
      "Epoch 100/800\n",
      "864/864 [==============================] - 7s 8ms/step - loss: 0.0023 - acc: 0.1678 - val_loss: 0.0036 - val_acc: 0.0928\n",
      "Epoch 101/800\n",
      "864/864 [==============================] - 7s 9ms/step - loss: 0.0025 - acc: 0.1319 - val_loss: 0.0036 - val_acc: 0.0825\n",
      "Epoch 102/800\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 0.0023 - acc: 0.1528 - val_loss: 0.0039 - val_acc: 0.2784\n",
      "Epoch 103/800\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 0.0023 - acc: 0.1296 - val_loss: 0.0042 - val_acc: 0.0722\n",
      "Epoch 104/800\n",
      "864/864 [==============================] - 7s 9ms/step - loss: 0.0024 - acc: 0.1493 - val_loss: 0.0037 - val_acc: 0.0619\n",
      "Epoch 105/800\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 0.0024 - acc: 0.1481 - val_loss: 0.0037 - val_acc: 0.0928\n",
      "Epoch 106/800\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 0.0024 - acc: 0.1065 - val_loss: 0.0048 - val_acc: 0.2268\n",
      "Epoch 107/800\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 0.0023 - acc: 0.2130 - val_loss: 0.0045 - val_acc: 0.0825\n",
      "Epoch 108/800\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 0.0027 - acc: 0.1030 - val_loss: 0.0035 - val_acc: 0.0928\n",
      "Epoch 109/800\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 0.0024 - acc: 0.2014 - val_loss: 0.0036 - val_acc: 0.2887\n",
      "Epoch 110/800\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 0.0022 - acc: 0.1366 - val_loss: 0.0035 - val_acc: 0.0412\n",
      "Epoch 111/800\n",
      "864/864 [==============================] - 8s 10ms/step - loss: 0.0022 - acc: 0.1389 - val_loss: 0.0042 - val_acc: 0.0928\n",
      "Epoch 112/800\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 0.0023 - acc: 0.1690 - val_loss: 0.0042 - val_acc: 0.1031\n",
      "Epoch 113/800\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 0.0023 - acc: 0.1644 - val_loss: 0.0038 - val_acc: 0.0825\n",
      "Epoch 114/800\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 0.0022 - acc: 0.1343 - val_loss: 0.0035 - val_acc: 0.1031\n",
      "Epoch 115/800\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 0.0022 - acc: 0.1748 - val_loss: 0.0035 - val_acc: 0.0825\n",
      "Epoch 116/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0022 - acc: 0.1238 - val_loss: 0.0048 - val_acc: 0.1134\n",
      "Epoch 117/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 9s 11ms/step - loss: 0.0021 - acc: 0.1123 - val_loss: 0.0034 - val_acc: 0.0722\n",
      "Epoch 118/800\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 0.0023 - acc: 0.1863 - val_loss: 0.0039 - val_acc: 0.2784\n",
      "Epoch 119/800\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 0.0022 - acc: 0.1806 - val_loss: 0.0041 - val_acc: 0.0825\n",
      "Epoch 120/800\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 0.0022 - acc: 0.1331 - val_loss: 0.0039 - val_acc: 0.0722\n",
      "Epoch 121/800\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 0.0021 - acc: 0.1771 - val_loss: 0.0039 - val_acc: 0.2680\n",
      "Epoch 122/800\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 0.0023 - acc: 0.1134 - val_loss: 0.0035 - val_acc: 0.0722\n",
      "Epoch 123/800\n",
      "864/864 [==============================] - 8s 10ms/step - loss: 0.0022 - acc: 0.1736 - val_loss: 0.0039 - val_acc: 0.2887\n",
      "Epoch 124/800\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 0.0021 - acc: 0.1516 - val_loss: 0.0039 - val_acc: 0.3299\n",
      "Epoch 125/800\n",
      "864/864 [==============================] - 8s 9ms/step - loss: 0.0021 - acc: 0.1134 - val_loss: 0.0042 - val_acc: 0.2577\n",
      "Epoch 126/800\n",
      "864/864 [==============================] - 8s 10ms/step - loss: 0.0022 - acc: 0.1898 - val_loss: 0.0039 - val_acc: 0.0309\n",
      "Epoch 127/800\n",
      "864/864 [==============================] - 8s 10ms/step - loss: 0.0026 - acc: 0.1377 - val_loss: 0.0037 - val_acc: 0.0722\n",
      "Epoch 128/800\n",
      "864/864 [==============================] - 8s 10ms/step - loss: 0.0022 - acc: 0.1447 - val_loss: 0.0040 - val_acc: 0.0722\n",
      "Epoch 129/800\n",
      "864/864 [==============================] - 8s 10ms/step - loss: 0.0021 - acc: 0.1667 - val_loss: 0.0046 - val_acc: 0.2268\n",
      "Epoch 130/800\n",
      "864/864 [==============================] - 9s 11ms/step - loss: 0.0021 - acc: 0.1343 - val_loss: 0.0038 - val_acc: 0.0825\n",
      "Epoch 131/800\n",
      "864/864 [==============================] - 9s 10ms/step - loss: 0.0021 - acc: 0.1852 - val_loss: 0.0045 - val_acc: 0.3093\n",
      "Epoch 132/800\n",
      "864/864 [==============================] - 9s 10ms/step - loss: 0.0021 - acc: 0.1400 - val_loss: 0.0038 - val_acc: 0.0825\n",
      "Epoch 133/800\n",
      "864/864 [==============================] - 9s 10ms/step - loss: 0.0021 - acc: 0.1771 - val_loss: 0.0040 - val_acc: 0.2474\n",
      "Epoch 134/800\n",
      "864/864 [==============================] - 9s 10ms/step - loss: 0.0020 - acc: 0.1366 - val_loss: 0.0041 - val_acc: 0.3196\n",
      "Epoch 135/800\n",
      "864/864 [==============================] - 9s 10ms/step - loss: 0.0021 - acc: 0.1817 - val_loss: 0.0039 - val_acc: 0.0928\n",
      "Epoch 136/800\n",
      "864/864 [==============================] - 9s 10ms/step - loss: 0.0021 - acc: 0.1343 - val_loss: 0.0042 - val_acc: 0.2784\n",
      "Epoch 137/800\n",
      "864/864 [==============================] - 9s 10ms/step - loss: 0.0022 - acc: 0.1562 - val_loss: 0.0040 - val_acc: 0.1546\n",
      "Epoch 138/800\n",
      "864/864 [==============================] - 9s 10ms/step - loss: 0.0020 - acc: 0.1389 - val_loss: 0.0041 - val_acc: 0.0825\n",
      "Epoch 139/800\n",
      "864/864 [==============================] - 10s 11ms/step - loss: 0.0019 - acc: 0.2118 - val_loss: 0.0041 - val_acc: 0.2990\n",
      "Epoch 140/800\n",
      "864/864 [==============================] - 9s 11ms/step - loss: 0.0019 - acc: 0.1863 - val_loss: 0.0038 - val_acc: 0.3196\n",
      "Epoch 141/800\n",
      "864/864 [==============================] - 10s 11ms/step - loss: 0.0019 - acc: 0.1412 - val_loss: 0.0044 - val_acc: 0.2371\n",
      "Epoch 142/800\n",
      "864/864 [==============================] - 10s 11ms/step - loss: 0.0020 - acc: 0.2083 - val_loss: 0.0037 - val_acc: 0.0825\n",
      "Epoch 143/800\n",
      "864/864 [==============================] - 10s 11ms/step - loss: 0.0020 - acc: 0.1250 - val_loss: 0.0040 - val_acc: 0.1031\n",
      "Epoch 144/800\n",
      "864/864 [==============================] - 10s 12ms/step - loss: 0.0020 - acc: 0.1771 - val_loss: 0.0035 - val_acc: 0.0722\n",
      "Epoch 145/800\n",
      "864/864 [==============================] - 10s 11ms/step - loss: 0.0020 - acc: 0.1308 - val_loss: 0.0040 - val_acc: 0.2577\n",
      "Epoch 146/800\n",
      "864/864 [==============================] - 10s 11ms/step - loss: 0.0019 - acc: 0.1447 - val_loss: 0.0040 - val_acc: 0.2990\n",
      "Epoch 147/800\n",
      "864/864 [==============================] - 11s 13ms/step - loss: 0.0019 - acc: 0.1840 - val_loss: 0.0042 - val_acc: 0.1031\n",
      "Epoch 148/800\n",
      "864/864 [==============================] - 11s 12ms/step - loss: 0.0019 - acc: 0.1574 - val_loss: 0.0042 - val_acc: 0.2577\n",
      "Epoch 149/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0018 - acc: 0.1782 - val_loss: 0.0037 - val_acc: 0.2887\n",
      "Epoch 150/800\n",
      "864/864 [==============================] - 11s 13ms/step - loss: 0.0020 - acc: 0.1331 - val_loss: 0.0040 - val_acc: 0.2474\n",
      "Epoch 151/800\n",
      "864/864 [==============================] - 10s 12ms/step - loss: 0.0019 - acc: 0.1968 - val_loss: 0.0036 - val_acc: 0.2990\n",
      "Epoch 152/800\n",
      "864/864 [==============================] - 13s 15ms/step - loss: 0.0020 - acc: 0.1620 - val_loss: 0.0039 - val_acc: 0.1340\n",
      "Epoch 153/800\n",
      "864/864 [==============================] - 11s 12ms/step - loss: 0.0019 - acc: 0.1771 - val_loss: 0.0043 - val_acc: 0.3093\n",
      "Epoch 154/800\n",
      "864/864 [==============================] - 10s 12ms/step - loss: 0.0019 - acc: 0.1944 - val_loss: 0.0038 - val_acc: 0.1649\n",
      "Epoch 155/800\n",
      "864/864 [==============================] - 13s 15ms/step - loss: 0.0018 - acc: 0.1343 - val_loss: 0.0038 - val_acc: 0.0515\n",
      "Epoch 156/800\n",
      "864/864 [==============================] - 12s 13ms/step - loss: 0.0018 - acc: 0.1759 - val_loss: 0.0044 - val_acc: 0.2784\n",
      "Epoch 157/800\n",
      "864/864 [==============================] - 11s 13ms/step - loss: 0.0019 - acc: 0.1505 - val_loss: 0.0038 - val_acc: 0.0515\n",
      "Epoch 158/800\n",
      "864/864 [==============================] - 13s 15ms/step - loss: 0.0019 - acc: 0.1620 - val_loss: 0.0040 - val_acc: 0.0515\n",
      "Epoch 159/800\n",
      "864/864 [==============================] - 11s 13ms/step - loss: 0.0019 - acc: 0.1377 - val_loss: 0.0044 - val_acc: 0.2474\n",
      "Epoch 160/800\n",
      "864/864 [==============================] - 11s 13ms/step - loss: 0.0019 - acc: 0.1771 - val_loss: 0.0036 - val_acc: 0.2784\n",
      "Epoch 161/800\n",
      "864/864 [==============================] - 11s 12ms/step - loss: 0.0018 - acc: 0.1736 - val_loss: 0.0038 - val_acc: 0.1031\n",
      "Epoch 162/800\n",
      "864/864 [==============================] - 11s 13ms/step - loss: 0.0018 - acc: 0.1817 - val_loss: 0.0038 - val_acc: 0.3093\n",
      "Epoch 163/800\n",
      "864/864 [==============================] - 11s 12ms/step - loss: 0.0018 - acc: 0.1539 - val_loss: 0.0041 - val_acc: 0.2887\n",
      "Epoch 164/800\n",
      "864/864 [==============================] - 11s 13ms/step - loss: 0.0018 - acc: 0.1551 - val_loss: 0.0041 - val_acc: 0.0928\n",
      "Epoch 165/800\n",
      "864/864 [==============================] - 11s 12ms/step - loss: 0.0019 - acc: 0.1887 - val_loss: 0.0041 - val_acc: 0.3196\n",
      "Epoch 166/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0018 - acc: 0.1574 - val_loss: 0.0045 - val_acc: 0.2680\n",
      "Epoch 167/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0018 - acc: 0.1910 - val_loss: 0.0040 - val_acc: 0.0825\n",
      "Epoch 168/800\n",
      "864/864 [==============================] - 11s 13ms/step - loss: 0.0018 - acc: 0.1620 - val_loss: 0.0044 - val_acc: 0.2680\n",
      "Epoch 169/800\n",
      "864/864 [==============================] - 11s 13ms/step - loss: 0.0017 - acc: 0.1690 - val_loss: 0.0042 - val_acc: 0.2784\n",
      "Epoch 170/800\n",
      "864/864 [==============================] - 11s 13ms/step - loss: 0.0017 - acc: 0.1609 - val_loss: 0.0036 - val_acc: 0.2887\n",
      "Epoch 171/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0018 - acc: 0.1829 - val_loss: 0.0041 - val_acc: 0.1753\n",
      "Epoch 172/800\n",
      "864/864 [==============================] - 11s 13ms/step - loss: 0.0020 - acc: 0.1690 - val_loss: 0.0042 - val_acc: 0.2680\n",
      "Epoch 173/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0019 - acc: 0.1528 - val_loss: 0.0038 - val_acc: 0.3093\n",
      "Epoch 174/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0019 - acc: 0.1667 - val_loss: 0.0042 - val_acc: 0.2165\n",
      "Epoch 175/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0017 - acc: 0.1875 - val_loss: 0.0040 - val_acc: 0.2371\n",
      "Epoch 176/800\n",
      "864/864 [==============================] - 13s 15ms/step - loss: 0.0017 - acc: 0.1759 - val_loss: 0.0041 - val_acc: 0.2680\n",
      "Epoch 177/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 12s 13ms/step - loss: 0.0017 - acc: 0.1655 - val_loss: 0.0046 - val_acc: 0.0619\n",
      "Epoch 178/800\n",
      "864/864 [==============================] - 12s 13ms/step - loss: 0.0018 - acc: 0.1782 - val_loss: 0.0043 - val_acc: 0.2371\n",
      "Epoch 179/800\n",
      "864/864 [==============================] - 11s 13ms/step - loss: 0.0021 - acc: 0.1898 - val_loss: 0.0045 - val_acc: 0.2990\n",
      "Epoch 180/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0017 - acc: 0.1609 - val_loss: 0.0050 - val_acc: 0.1134\n",
      "Epoch 181/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0016 - acc: 0.1748 - val_loss: 0.0042 - val_acc: 0.2680\n",
      "Epoch 182/800\n",
      "864/864 [==============================] - 11s 13ms/step - loss: 0.0016 - acc: 0.2025 - val_loss: 0.0044 - val_acc: 0.2990\n",
      "Epoch 183/800\n",
      "864/864 [==============================] - 11s 13ms/step - loss: 0.0015 - acc: 0.1701 - val_loss: 0.0038 - val_acc: 0.2268\n",
      "Epoch 184/800\n",
      "864/864 [==============================] - 11s 13ms/step - loss: 0.0016 - acc: 0.1840 - val_loss: 0.0042 - val_acc: 0.2784\n",
      "Epoch 185/800\n",
      "864/864 [==============================] - 11s 13ms/step - loss: 0.0016 - acc: 0.1134 - val_loss: 0.0052 - val_acc: 0.2887\n",
      "Epoch 186/800\n",
      "864/864 [==============================] - 11s 13ms/step - loss: 0.0020 - acc: 0.2002 - val_loss: 0.0031 - val_acc: 0.1546\n",
      "Epoch 187/800\n",
      "864/864 [==============================] - 11s 13ms/step - loss: 0.0017 - acc: 0.1701 - val_loss: 0.0042 - val_acc: 0.2577\n",
      "Epoch 188/800\n",
      "864/864 [==============================] - 13s 15ms/step - loss: 0.0016 - acc: 0.1887 - val_loss: 0.0038 - val_acc: 0.2887\n",
      "Epoch 189/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0017 - acc: 0.1875 - val_loss: 0.0039 - val_acc: 0.3093\n",
      "Epoch 190/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0016 - acc: 0.1759 - val_loss: 0.0039 - val_acc: 0.1649\n",
      "Epoch 191/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0015 - acc: 0.1655 - val_loss: 0.0042 - val_acc: 0.2887\n",
      "Epoch 192/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0015 - acc: 0.1840 - val_loss: 0.0041 - val_acc: 0.2577\n",
      "Epoch 193/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0015 - acc: 0.1968 - val_loss: 0.0045 - val_acc: 0.1134\n",
      "Epoch 194/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0016 - acc: 0.1840 - val_loss: 0.0036 - val_acc: 0.2680\n",
      "Epoch 195/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0016 - acc: 0.1806 - val_loss: 0.0049 - val_acc: 0.2784\n",
      "Epoch 196/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0015 - acc: 0.1759 - val_loss: 0.0042 - val_acc: 0.2680\n",
      "Epoch 197/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0015 - acc: 0.1910 - val_loss: 0.0041 - val_acc: 0.2990\n",
      "Epoch 198/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0015 - acc: 0.1586 - val_loss: 0.0045 - val_acc: 0.2680\n",
      "Epoch 199/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0015 - acc: 0.1979 - val_loss: 0.0037 - val_acc: 0.2577\n",
      "Epoch 200/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0015 - acc: 0.1840 - val_loss: 0.0040 - val_acc: 0.2268\n",
      "Epoch 201/800\n",
      "864/864 [==============================] - 15s 17ms/step - loss: 0.0014 - acc: 0.1609 - val_loss: 0.0048 - val_acc: 0.0825\n",
      "Epoch 202/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0015 - acc: 0.1678 - val_loss: 0.0043 - val_acc: 0.0722\n",
      "Epoch 203/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0017 - acc: 0.1725 - val_loss: 0.0040 - val_acc: 0.2474\n",
      "Epoch 204/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0015 - acc: 0.2106 - val_loss: 0.0041 - val_acc: 0.1856\n",
      "Epoch 205/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0014 - acc: 0.1863 - val_loss: 0.0043 - val_acc: 0.1443\n",
      "Epoch 206/800\n",
      "864/864 [==============================] - 12s 14ms/step - loss: 0.0014 - acc: 0.1898 - val_loss: 0.0045 - val_acc: 0.1237\n",
      "Epoch 207/800\n",
      "864/864 [==============================] - 13s 15ms/step - loss: 0.0013 - acc: 0.1968 - val_loss: 0.0042 - val_acc: 0.2680\n",
      "Epoch 208/800\n",
      "864/864 [==============================] - 13s 15ms/step - loss: 0.0014 - acc: 0.1690 - val_loss: 0.0055 - val_acc: 0.2062\n",
      "Epoch 209/800\n",
      "864/864 [==============================] - 13s 15ms/step - loss: 0.0014 - acc: 0.1759 - val_loss: 0.0044 - val_acc: 0.2784\n",
      "Epoch 210/800\n",
      "864/864 [==============================] - 13s 15ms/step - loss: 0.0013 - acc: 0.1840 - val_loss: 0.0044 - val_acc: 0.2990\n",
      "Epoch 211/800\n",
      "864/864 [==============================] - 13s 15ms/step - loss: 0.0013 - acc: 0.1655 - val_loss: 0.0043 - val_acc: 0.2887\n",
      "Epoch 212/800\n",
      "864/864 [==============================] - 13s 15ms/step - loss: 0.0013 - acc: 0.1597 - val_loss: 0.0039 - val_acc: 0.1134\n",
      "Epoch 213/800\n",
      "864/864 [==============================] - 13s 15ms/step - loss: 0.0013 - acc: 0.1933 - val_loss: 0.0047 - val_acc: 0.2784\n",
      "Epoch 214/800\n",
      "864/864 [==============================] - 13s 15ms/step - loss: 0.0014 - acc: 0.1887 - val_loss: 0.0037 - val_acc: 0.1856\n",
      "Epoch 215/800\n",
      "864/864 [==============================] - 13s 15ms/step - loss: 0.0012 - acc: 0.1748 - val_loss: 0.0042 - val_acc: 0.1546\n",
      "Epoch 216/800\n",
      "864/864 [==============================] - 13s 15ms/step - loss: 0.0013 - acc: 0.1713 - val_loss: 0.0042 - val_acc: 0.1546\n",
      "Epoch 217/800\n",
      "864/864 [==============================] - 13s 15ms/step - loss: 0.0012 - acc: 0.1852 - val_loss: 0.0042 - val_acc: 0.2062\n",
      "Epoch 218/800\n",
      "864/864 [==============================] - 13s 15ms/step - loss: 0.0014 - acc: 0.1863 - val_loss: 0.0041 - val_acc: 0.0515\n",
      "Epoch 219/800\n",
      "864/864 [==============================] - 13s 15ms/step - loss: 0.0016 - acc: 0.1377 - val_loss: 0.0045 - val_acc: 0.0515\n",
      "Epoch 220/800\n",
      "864/864 [==============================] - 13s 15ms/step - loss: 0.0015 - acc: 0.1887 - val_loss: 0.0040 - val_acc: 0.1031\n",
      "Epoch 221/800\n",
      "864/864 [==============================] - 13s 15ms/step - loss: 0.0012 - acc: 0.1481 - val_loss: 0.0038 - val_acc: 0.2474\n",
      "Epoch 222/800\n",
      "864/864 [==============================] - 13s 16ms/step - loss: 0.0013 - acc: 0.1863 - val_loss: 0.0042 - val_acc: 0.1340\n",
      "Epoch 223/800\n",
      "864/864 [==============================] - 13s 16ms/step - loss: 0.0013 - acc: 0.1713 - val_loss: 0.0046 - val_acc: 0.2784\n",
      "Epoch 224/800\n",
      "864/864 [==============================] - 15s 18ms/step - loss: 0.0013 - acc: 0.1690 - val_loss: 0.0037 - val_acc: 0.2577\n",
      "Epoch 225/800\n",
      "864/864 [==============================] - 14s 16ms/step - loss: 0.0012 - acc: 0.1852 - val_loss: 0.0042 - val_acc: 0.2062\n",
      "Epoch 226/800\n",
      "864/864 [==============================] - 14s 16ms/step - loss: 0.0011 - acc: 0.1481 - val_loss: 0.0046 - val_acc: 0.1134\n",
      "Epoch 227/800\n",
      "864/864 [==============================] - 14s 16ms/step - loss: 0.0012 - acc: 0.1817 - val_loss: 0.0045 - val_acc: 0.1134\n",
      "Epoch 228/800\n",
      "864/864 [==============================] - 14s 16ms/step - loss: 0.0012 - acc: 0.1701 - val_loss: 0.0033 - val_acc: 0.1340\n",
      "Epoch 229/800\n",
      "864/864 [==============================] - 14s 16ms/step - loss: 0.0012 - acc: 0.2025 - val_loss: 0.0041 - val_acc: 0.0722\n",
      "Epoch 230/800\n",
      "864/864 [==============================] - 14s 16ms/step - loss: 0.0012 - acc: 0.1806 - val_loss: 0.0051 - val_acc: 0.1856\n",
      "Epoch 231/800\n",
      "864/864 [==============================] - 14s 16ms/step - loss: 0.0012 - acc: 0.1690 - val_loss: 0.0039 - val_acc: 0.0619\n",
      "Epoch 232/800\n",
      "864/864 [==============================] - 14s 16ms/step - loss: 0.0012 - acc: 0.1678 - val_loss: 0.0040 - val_acc: 0.1753\n",
      "Epoch 233/800\n",
      "864/864 [==============================] - 14s 16ms/step - loss: 0.0012 - acc: 0.1759 - val_loss: 0.0041 - val_acc: 0.2371\n",
      "Epoch 234/800\n",
      "864/864 [==============================] - 14s 16ms/step - loss: 0.0011 - acc: 0.1632 - val_loss: 0.0042 - val_acc: 0.2062\n",
      "Epoch 235/800\n",
      "864/864 [==============================] - 14s 16ms/step - loss: 0.0011 - acc: 0.1863 - val_loss: 0.0047 - val_acc: 0.1443\n",
      "Epoch 236/800\n",
      "864/864 [==============================] - 14s 16ms/step - loss: 0.0011 - acc: 0.1713 - val_loss: 0.0041 - val_acc: 0.2165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/800\n",
      "864/864 [==============================] - 15s 17ms/step - loss: 0.0012 - acc: 0.1597 - val_loss: 0.0042 - val_acc: 0.0928\n",
      "Epoch 238/800\n",
      "864/864 [==============================] - 16s 18ms/step - loss: 0.0012 - acc: 0.1678 - val_loss: 0.0048 - val_acc: 0.1753\n",
      "Epoch 239/800\n",
      "864/864 [==============================] - 14s 17ms/step - loss: 0.0012 - acc: 0.1620 - val_loss: 0.0046 - val_acc: 0.0722\n",
      "Epoch 240/800\n",
      "864/864 [==============================] - 14s 16ms/step - loss: 0.0011 - acc: 0.1806 - val_loss: 0.0046 - val_acc: 0.1031\n",
      "Epoch 241/800\n",
      "864/864 [==============================] - 14s 16ms/step - loss: 0.0012 - acc: 0.1771 - val_loss: 0.0043 - val_acc: 0.2577\n",
      "Epoch 242/800\n",
      "864/864 [==============================] - 14s 16ms/step - loss: 0.0011 - acc: 0.1644 - val_loss: 0.0045 - val_acc: 0.1134\n",
      "Epoch 243/800\n",
      "864/864 [==============================] - 14s 17ms/step - loss: 0.0011 - acc: 0.1840 - val_loss: 0.0048 - val_acc: 0.1340\n",
      "Epoch 244/800\n",
      "864/864 [==============================] - 14s 16ms/step - loss: 0.0012 - acc: 0.1956 - val_loss: 0.0045 - val_acc: 0.1649\n",
      "Epoch 245/800\n",
      "864/864 [==============================] - 15s 18ms/step - loss: 0.0011 - acc: 0.1713 - val_loss: 0.0045 - val_acc: 0.2165\n",
      "Epoch 246/800\n",
      "864/864 [==============================] - 14s 17ms/step - loss: 0.0012 - acc: 0.1725 - val_loss: 0.0041 - val_acc: 0.1134\n",
      "Epoch 247/800\n",
      "864/864 [==============================] - 15s 17ms/step - loss: 0.0012 - acc: 0.1759 - val_loss: 0.0040 - val_acc: 0.1443\n",
      "Epoch 248/800\n",
      "864/864 [==============================] - 14s 17ms/step - loss: 0.0011 - acc: 0.1933 - val_loss: 0.0047 - val_acc: 0.0619\n",
      "Epoch 249/800\n",
      "864/864 [==============================] - 17s 19ms/step - loss: 0.0011 - acc: 0.1725 - val_loss: 0.0052 - val_acc: 0.1753\n",
      "Epoch 250/800\n",
      "864/864 [==============================] - 15s 17ms/step - loss: 0.0011 - acc: 0.1991 - val_loss: 0.0037 - val_acc: 0.2165\n",
      "Epoch 251/800\n",
      "864/864 [==============================] - 15s 17ms/step - loss: 0.0013 - acc: 0.1898 - val_loss: 0.0060 - val_acc: 0.1031\n",
      "Epoch 252/800\n",
      "864/864 [==============================] - 15s 17ms/step - loss: 0.0011 - acc: 0.1944 - val_loss: 0.0039 - val_acc: 0.1237\n",
      "Epoch 253/800\n",
      "864/864 [==============================] - 15s 17ms/step - loss: 0.0012 - acc: 0.1782 - val_loss: 0.0047 - val_acc: 0.1649\n",
      "Epoch 254/800\n",
      "864/864 [==============================] - 16s 18ms/step - loss: 0.0010 - acc: 0.1887 - val_loss: 0.0050 - val_acc: 0.1753\n",
      "Epoch 255/800\n",
      "864/864 [==============================] - 15s 18ms/step - loss: 0.0010 - acc: 0.1944 - val_loss: 0.0043 - val_acc: 0.0825\n",
      "Epoch 256/800\n",
      "864/864 [==============================] - 15s 18ms/step - loss: 0.0011 - acc: 0.1863 - val_loss: 0.0042 - val_acc: 0.1959\n",
      "Epoch 257/800\n",
      "864/864 [==============================] - 15s 18ms/step - loss: 0.0011 - acc: 0.1852 - val_loss: 0.0049 - val_acc: 0.1237\n",
      "Epoch 258/800\n",
      "864/864 [==============================] - 15s 18ms/step - loss: 0.0011 - acc: 0.1991 - val_loss: 0.0048 - val_acc: 0.0825\n",
      "Epoch 259/800\n",
      "864/864 [==============================] - 15s 18ms/step - loss: 0.0010 - acc: 0.1979 - val_loss: 0.0041 - val_acc: 0.0722\n",
      "Epoch 260/800\n",
      "864/864 [==============================] - 15s 18ms/step - loss: 0.0010 - acc: 0.2245 - val_loss: 0.0039 - val_acc: 0.1031\n",
      "Epoch 261/800\n",
      "864/864 [==============================] - 16s 18ms/step - loss: 0.0011 - acc: 0.1736 - val_loss: 0.0053 - val_acc: 0.1031\n",
      "Epoch 262/800\n",
      "864/864 [==============================] - 16s 18ms/step - loss: 0.0010 - acc: 0.1875 - val_loss: 0.0051 - val_acc: 0.0619\n",
      "Epoch 263/800\n",
      "864/864 [==============================] - 16s 19ms/step - loss: 0.0011 - acc: 0.1944 - val_loss: 0.0048 - val_acc: 0.1031\n",
      "Epoch 264/800\n",
      "864/864 [==============================] - 16s 18ms/step - loss: 9.8890e-04 - acc: 0.1829 - val_loss: 0.0048 - val_acc: 0.1856\n",
      "Epoch 265/800\n",
      "864/864 [==============================] - 18s 21ms/step - loss: 0.0010 - acc: 0.1921 - val_loss: 0.0041 - val_acc: 0.0722\n",
      "Epoch 266/800\n",
      "864/864 [==============================] - 16s 18ms/step - loss: 0.0010 - acc: 0.2350 - val_loss: 0.0058 - val_acc: 0.2474\n",
      "Epoch 267/800\n",
      "864/864 [==============================] - 16s 18ms/step - loss: 0.0010 - acc: 0.1898 - val_loss: 0.0049 - val_acc: 0.2062\n",
      "Epoch 268/800\n",
      "864/864 [==============================] - 17s 19ms/step - loss: 0.0010 - acc: 0.1806 - val_loss: 0.0049 - val_acc: 0.0928\n",
      "Epoch 269/800\n",
      "864/864 [==============================] - 17s 20ms/step - loss: 0.0010 - acc: 0.2141 - val_loss: 0.0057 - val_acc: 0.1237\n",
      "Epoch 270/800\n",
      "864/864 [==============================] - 17s 19ms/step - loss: 9.8120e-04 - acc: 0.2025 - val_loss: 0.0053 - val_acc: 0.0619\n",
      "Epoch 271/800\n",
      "864/864 [==============================] - 16s 18ms/step - loss: 9.6987e-04 - acc: 0.1979 - val_loss: 0.0053 - val_acc: 0.1031\n",
      "Epoch 272/800\n",
      "864/864 [==============================] - 16s 18ms/step - loss: 0.0010 - acc: 0.1956 - val_loss: 0.0054 - val_acc: 0.0722\n",
      "Epoch 273/800\n",
      "864/864 [==============================] - 16s 18ms/step - loss: 0.0010 - acc: 0.1887 - val_loss: 0.0054 - val_acc: 0.0619\n",
      "Epoch 274/800\n",
      "864/864 [==============================] - 16s 18ms/step - loss: 0.0011 - acc: 0.1817 - val_loss: 0.0041 - val_acc: 0.0825\n",
      "Epoch 275/800\n",
      "864/864 [==============================] - 16s 19ms/step - loss: 0.0010 - acc: 0.2014 - val_loss: 0.0050 - val_acc: 0.1031\n",
      "Epoch 276/800\n",
      "864/864 [==============================] - 16s 19ms/step - loss: 9.9292e-04 - acc: 0.1875 - val_loss: 0.0048 - val_acc: 0.0825\n",
      "Epoch 277/800\n",
      "864/864 [==============================] - 16s 19ms/step - loss: 9.6443e-04 - acc: 0.2257 - val_loss: 0.0050 - val_acc: 0.0825\n",
      "Epoch 278/800\n",
      "864/864 [==============================] - 16s 19ms/step - loss: 9.4401e-04 - acc: 0.1968 - val_loss: 0.0050 - val_acc: 0.0619\n",
      "Epoch 279/800\n",
      "864/864 [==============================] - 16s 19ms/step - loss: 0.0010 - acc: 0.2211 - val_loss: 0.0050 - val_acc: 0.1340\n",
      "Epoch 280/800\n",
      "864/864 [==============================] - 16s 19ms/step - loss: 0.0010 - acc: 0.2141 - val_loss: 0.0049 - val_acc: 0.0928\n",
      "Epoch 281/800\n",
      "864/864 [==============================] - 17s 19ms/step - loss: 9.7236e-04 - acc: 0.2164 - val_loss: 0.0047 - val_acc: 0.0619\n",
      "Epoch 282/800\n",
      "864/864 [==============================] - 16s 19ms/step - loss: 9.7413e-04 - acc: 0.2118 - val_loss: 0.0055 - val_acc: 0.0619\n",
      "Epoch 283/800\n",
      "864/864 [==============================] - 17s 20ms/step - loss: 9.5392e-04 - acc: 0.2188 - val_loss: 0.0050 - val_acc: 0.0722\n",
      "Epoch 284/800\n",
      "864/864 [==============================] - 16s 19ms/step - loss: 9.6926e-04 - acc: 0.2211 - val_loss: 0.0049 - val_acc: 0.2474\n",
      "Epoch 285/800\n",
      "864/864 [==============================] - 17s 19ms/step - loss: 9.6513e-04 - acc: 0.2326 - val_loss: 0.0050 - val_acc: 0.0619\n",
      "Epoch 286/800\n",
      "864/864 [==============================] - 17s 19ms/step - loss: 9.5304e-04 - acc: 0.2002 - val_loss: 0.0048 - val_acc: 0.0825\n",
      "Epoch 287/800\n",
      "864/864 [==============================] - 17s 19ms/step - loss: 9.1300e-04 - acc: 0.1898 - val_loss: 0.0048 - val_acc: 0.1237\n",
      "Epoch 288/800\n",
      "864/864 [==============================] - 17s 19ms/step - loss: 9.0250e-04 - acc: 0.2164 - val_loss: 0.0056 - val_acc: 0.0619\n",
      "Epoch 289/800\n",
      "864/864 [==============================] - 17s 20ms/step - loss: 9.0525e-04 - acc: 0.2315 - val_loss: 0.0050 - val_acc: 0.0619\n",
      "Epoch 290/800\n",
      "864/864 [==============================] - 17s 20ms/step - loss: 9.3374e-04 - acc: 0.1933 - val_loss: 0.0049 - val_acc: 0.1031\n",
      "Epoch 291/800\n",
      "864/864 [==============================] - 17s 20ms/step - loss: 9.6187e-04 - acc: 0.2025 - val_loss: 0.0050 - val_acc: 0.0825\n",
      "Epoch 292/800\n",
      "864/864 [==============================] - 17s 20ms/step - loss: 9.7282e-04 - acc: 0.2141 - val_loss: 0.0054 - val_acc: 0.0722\n",
      "Epoch 293/800\n",
      "864/864 [==============================] - 17s 20ms/step - loss: 9.2654e-04 - acc: 0.2488 - val_loss: 0.0052 - val_acc: 0.0722\n",
      "Epoch 294/800\n",
      "864/864 [==============================] - 17s 20ms/step - loss: 8.8408e-04 - acc: 0.2350 - val_loss: 0.0055 - val_acc: 0.1134\n",
      "Epoch 295/800\n",
      "864/864 [==============================] - 17s 20ms/step - loss: 9.2414e-04 - acc: 0.2477 - val_loss: 0.0053 - val_acc: 0.2371\n",
      "Epoch 296/800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "864/864 [==============================] - 17s 20ms/step - loss: 8.8976e-04 - acc: 0.2257 - val_loss: 0.0048 - val_acc: 0.1340\n",
      "Epoch 297/800\n",
      "864/864 [==============================] - 17s 20ms/step - loss: 8.8232e-04 - acc: 0.2326 - val_loss: 0.0049 - val_acc: 0.2165\n",
      "Epoch 298/800\n",
      "864/864 [==============================] - 17s 20ms/step - loss: 0.0011 - acc: 0.2188 - val_loss: 0.0060 - val_acc: 0.2268\n",
      "Epoch 299/800\n",
      "864/864 [==============================] - 17s 20ms/step - loss: 0.0011 - acc: 0.2095 - val_loss: 0.0040 - val_acc: 0.0722\n",
      "Epoch 300/800\n",
      "864/864 [==============================] - 17s 20ms/step - loss: 9.8916e-04 - acc: 0.2130 - val_loss: 0.0058 - val_acc: 0.0619\n",
      "Epoch 301/800\n",
      "864/864 [==============================] - 18s 20ms/step - loss: 9.4931e-04 - acc: 0.2303 - val_loss: 0.0053 - val_acc: 0.1649\n",
      "Epoch 302/800\n",
      "864/864 [==============================] - 17s 20ms/step - loss: 9.3368e-04 - acc: 0.2095 - val_loss: 0.0053 - val_acc: 0.0619\n",
      "Epoch 303/800\n",
      "864/864 [==============================] - 17s 20ms/step - loss: 9.0311e-04 - acc: 0.2222 - val_loss: 0.0058 - val_acc: 0.2371\n",
      "Epoch 304/800\n",
      "864/864 [==============================] - 18s 20ms/step - loss: 8.7691e-04 - acc: 0.2211 - val_loss: 0.0043 - val_acc: 0.0825\n",
      "Epoch 305/800\n",
      "864/864 [==============================] - 18s 21ms/step - loss: 8.6706e-04 - acc: 0.2292 - val_loss: 0.0046 - val_acc: 0.2577\n",
      "Epoch 306/800\n",
      "864/864 [==============================] - 18s 20ms/step - loss: 9.0181e-04 - acc: 0.2384 - val_loss: 0.0056 - val_acc: 0.0825\n",
      "Epoch 307/800\n",
      "864/864 [==============================] - 18s 20ms/step - loss: 9.1811e-04 - acc: 0.2373 - val_loss: 0.0059 - val_acc: 0.0722\n",
      "Epoch 308/800\n",
      "864/864 [==============================] - 18s 21ms/step - loss: 9.1378e-04 - acc: 0.2164 - val_loss: 0.0054 - val_acc: 0.0722\n",
      "Epoch 309/800\n",
      "864/864 [==============================] - 18s 21ms/step - loss: 8.6572e-04 - acc: 0.2049 - val_loss: 0.0050 - val_acc: 0.0619\n",
      "Epoch 310/800\n",
      "864/864 [==============================] - 18s 20ms/step - loss: 8.7966e-04 - acc: 0.2303 - val_loss: 0.0054 - val_acc: 0.0825\n",
      "Epoch 311/800\n",
      "864/864 [==============================] - 18s 21ms/step - loss: 8.4316e-04 - acc: 0.2407 - val_loss: 0.0046 - val_acc: 0.2474\n",
      "Epoch 312/800\n",
      "864/864 [==============================] - 18s 21ms/step - loss: 8.5402e-04 - acc: 0.2188 - val_loss: 0.0057 - val_acc: 0.2474\n",
      "Epoch 313/800\n",
      "864/864 [==============================] - 18s 21ms/step - loss: 8.5867e-04 - acc: 0.2338 - val_loss: 0.0047 - val_acc: 0.1031\n",
      "Epoch 314/800\n",
      "864/864 [==============================] - 18s 21ms/step - loss: 8.5069e-04 - acc: 0.2569 - val_loss: 0.0056 - val_acc: 0.2371\n",
      "Epoch 315/800\n",
      "864/864 [==============================] - 18s 21ms/step - loss: 9.1377e-04 - acc: 0.2292 - val_loss: 0.0055 - val_acc: 0.2165\n",
      "Epoch 316/800\n",
      "192/864 [=====>........................] - ETA: 14s - loss: 0.0010 - acc: 0.2604"
     ]
    }
   ],
   "source": [
    "res = model.fit(X, y, epochs=800, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_training_results(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# Getting predictions by predicting from the last available X variable\n",
    "yhat = model.predict(X[-1].reshape(1, n_per_in, n_features)).tolist()[0]\n",
    "\n",
    "# Transforming values back to their normal prices\n",
    "yhat = scaler.inverse_transform(np.array(yhat).reshape(-1,1)).tolist()\n",
    "\n",
    "# Getting the actual values from the last available y variable which correspond to its respective X variable\n",
    "actual = scaler.inverse_transform(y[-1].reshape(-1,1))\n",
    "\n",
    "# Printing and plotting those predictions\n",
    "print(\"Predicted Prices:\\n\", yhat)\n",
    "plt.plot(yhat, label='Predicted')\n",
    "\n",
    "# Printing and plotting the actual values\n",
    "print(\"\\nActual Prices:\\n\", actual.tolist())\n",
    "plt.plot(actual.tolist(), label='Actual')\n",
    "\n",
    "plt.title(f\"Predicted vs Actual Closing Prices\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.legend()\n",
    "plt.savefig(\"BTC_validation.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Predicting off of y because it contains the most recent dates\n",
    "yhat = model.predict(np.array(df.tail(n_per_in)).reshape(1, n_per_in, n_features)).tolist()[0]\n",
    "\n",
    "# Transforming the predicted values back to their original prices\n",
    "yhat = scaler.inverse_transform(np.array(yhat).reshape(-1,1)).tolist()\n",
    "\n",
    "# Creating a DF of the predicted prices\n",
    "preds = pd.DataFrame(yhat, index=pd.date_range(start=df.index[-1], periods=len(yhat), freq=\"D\"), columns=df.columns)\n",
    "\n",
    "# Printing the predicted prices\n",
    "print(preds)\n",
    "\n",
    "# Number of periods back to visualize the actual values\n",
    "pers = 10\n",
    "\n",
    "# Transforming the actual values to their original price\n",
    "actual = pd.DataFrame(scaler.inverse_transform(df[[\"Close\"]].tail(pers)), index=df.Close.tail(pers).index, columns=df.columns).append(preds.head(1))\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(actual, label=\"Actual Prices\")\n",
    "plt.plot(preds, label=\"Predicted Prices\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.xlabel(\"Dates\")\n",
    "plt.title(f\"Forecasting the next {len(yhat)} days\")\n",
    "plt.legend()\n",
    "plt.savefig(\"BTC_predictions.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
